<!doctype html>
<html  lang="en">
    <meta charset="utf-8">

    <style>
        body {padding-top: 3.5rem;}
    </style>

    <header>
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
        <link rel="stylesheet" href="styles/style.css">

        <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark">
            <a class="navbar-brand" href="index.html">CovViz</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExampleDefault" aria-controls="navbarsExampleDefault" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarsExampleDefault">
                <ul class="navbar-nav mr-auto">
                    <li class="nav-item active">
                        <a class="nav-link" href="index.html">Visualization <span class="sr-only">(current)</span></a>
                    </li>
                </ul>
            </div>
        </nav>


    </header>



    <body>

        <div class="jumbotron">
            <div class="container">
                <h1 class="display-3">Visualizing Fuzzer Coverage</h1>

                <!--<h2>Motivation</h2>-->
<p>Our visualization framework enables a program analyst to understand inputs generated as part of a program testing campaign (also called fuzzing). To ensure a successful test, the generate inputs should actuate, or “cover,” as much of the original program as possible. While many tools exist to automatically generate inputs for this type of testing, they typically have poorly-designed user interfaces which prevent an analyst from understanding how their testing campaign is performing over time.</p>

<p>To solve this problem, we have created an interactive visualization showing how much of a program is covered by fuzzer-generated inputs over time. Using a series of provided scripts, an analyst can transform their fuzzing campaign into input data for the visualization and then explore the data and gain a better understanding of what’s going on.</p>

<p>Our visualization enables an analyst to quickly see how well individual functions within a program are being tested over time and how significant each of those functions is. An analyst can then select any function of interest to see additional coverage information about the code within the selected function. Through our visualization, we hope to help analysts understand both where their testing is failing and when it stops getting new results. Through interviews with our expert, we believe this visualization accomplishes this goal.</p>

            </div>
        </div>


        <div class="container">
            <!-- Example row of columns -->
            <div class="row">
                <div class="col-lg-6">
                    <h2>Data</h2>
<p>We used a dataset from <a href="https://rode0day.mit.edu">Rode0day</a>, a bug-finding competition that challenges software testers to try finding bugs in provided programs. Throughout the competition, teams generate and provide inputs that they suspect will trigger bugs.</p>

<p>For our visualization, we selected all the inputs uploaded for the challenge &quot;TinyExpr&quot; by team <a href="https://rode0day.mit.edu/profile/REDQUEEN">REDQUEEN</a>. For each of the 835 inputs this team provided, we used a series of scripts to measure which parts of the program they covered. We saved this data in JSON mapping timestamps to a list of basic blocks covered at each time. We also conducted an analysis of the “TinyExpr” program in order to generate a list of functions and the basic blocks contained within each and store the information in JSON. These scripts use the open source tools DynamoRIO, Ghidra, and Radare2. All of these scripts are available in our repository.</p>

<p>In data visualization terms, our dataset can be seen as a table of items and attributes. Each item (row) corresponds to a particular input file, and the attributes (columns) include a sequential timestamp and a combined list of categorical blocks. </p>
                </div>
                <div class="col-lg-6">
                  <h2>Task Analysis</h2>
                  <p>To better understand the tasks our visualization could enable, we conducted an interview with Joshua Bundt, a PhD student researching program fuzzing and testing. Through this interview, we learned that current fuzzing tools are mostly text-based and employ very basic visualizations (often just text-based tables). Joshua expressed a desire to have a graphical tool which could help him understand when to stop a particular fuzzing campaign. We translated this into the following domain tasks:</p>
                  <ol>
                    <li>Finding out whether the program coverage is improving over time;</li>
                    <li>Analyzing the set of inputs with similar program coverage;</li>
                    <li>Locating the areas in program which do not get any coverage;</li>
                    <li>Pinpointing input files with anomalous coverage paths.</li>
                  </ol>
                  <p>Our visualization was focused on the first three tasks.</p>

                </div>
            </div>
            <div class="row">
                <div class="col-lg-6">
                    <h2>Design Process</h2>
<p>Our design process began with each member of our team creating a series of sketches. After discussing these sketches, we agreed upon a design that allowed users to show overall program coverage over time and to view the coverage of a selected function. </p>

<p>While these high-level concepts remained the same throughout our design process, many significant changes were made during time as we learned more about user needs.</p>

<p>During our interview, we realized the importance of showing the overall coverage of the program at any given point in time. To enable this, we decided to add additional line graphs below each figure showing the total program coverage as well as the selected function’s coverage over time.</p>

<p>Through our usability testing phase, we noticed many users misunderstood or entirely missed features. We made a number of changes to help with this. To ensure users understood that the rectangles on the left side represent functions, we automatically add labels to the larger functions (which have space for labels). We also added a tooltip to this section and clearly highlight both the moused-over as well as the currently-selected function. Beyond this, we added a help page that provides a quick overview of the visualization and how to use it.</p>

                </div>
                <div class="col-lg-6">
                  <h2>Final Visualization</h2>
                  <p>Our final visualization is split into two primary components, an overview of the entire program and a detailed view of a selected function. Within the <em>Program Overview</em>, a series of rectangles are shown representing functions in the program. The area of a rectangle encodes the size of the function it represents, while the color encodes how much of the function is covered. We chose to use area to represent function size because larger functions are more important and should contribute more to the overall coverage a viewer perceives. In data visualization terms, the visualization type is a treemap with area as the mark, and size and color as the channels. We used a sequential color scale with two hues, starting at a light yellow to indicate a function is uncovered and then transitioning to a saturated green to indicate a fully-covered function. The yellow color draws a viewer’s attention to a problem (an uncovered function) while saturated green colors are used to indicate that the function was successfully covered. </p>

<p>In the <em>Program Overview</em>, a user can view specific information by mousing over a rectangle which shows a tooltip and highlights the rectangle with a red border. If a user clicks on a function, it will be given a yellow border and the right half of the visualization will be updated to focus on this function.</p>

<p>Beneath the program interview, a play/pause button allows a user to start or stop an animation showing how coverage changed over time. Under this, a line graph shows how the inputs submitted over time changed the total cumulative coverage of the program. This line graph can also be brushed to select a subregion of the inputs uploaded.</p>

<p>On the right side of the visualization, the detailed view of a selected function is shown. When the visualization is first loaded, the “main” function is shown, but after a user selects another function in the <em>Program Overview</em>, that function is loaded. The top half of this visualization shows a network graph view of the basic blocks contained within the function (generated by Radare2 as driven by our scripts). The blocks are colored green once they are covered by an input at or prior to the currently selected time. This graph uses EasyPZ to enable a user to navigate through the potentially large graph.</p>

<p>Below the function disassembly network graph, a line graph is shown representing the coverage of the selected function over time.</p>

                </div>
            </div>
            <div class="row">
                <div class="col-lg-6">
                    <h2>Data Analysis</h2>
                    <p>Through our visualization of inputs generated to <em>TinyExpr</em>, we noticed that the overall program coverage rapidly increased in the first 10 inputs. After these inputs, the change in coverage increased more slowly for the rest of the first 100 inputs. For the remaining 735 inputs, coverage increased very slowly. This indicates that the analysis suffered from diminishing returns, and that the program testing could have stopped after the first hundred inputs and generated similar results in a shorter time.</p>

                    <p>Our visualization also highlighted the fact that some medium-sized functions in the program remained relatively uncovered throughout the entire testing campaign. Specifically this revealed that the functions <em>fac, sqrt, ncr</em> and <em>cn</em> were completely uncovered at the end of the campaign.</p>

                    <p>Across other functions, such as <em>te_eval</em> and <em>te_free_parameters</em>, some parts were covered while others were not. Through our visualization, we can see that in the te_eval function, a number of cases in a switch were uncovered. This information can be used to update the input generation strategies in the fuzzing software to improve the testing campaign’s effectiveness.</p>

                </div>
                <div class="col-lg-6">
                    <h2>Conclusion</h2>
<p>For this project, we created a system to analyze a program and many test inputs to measure the coverage that these inputs generated over time. We then created an interactive visualization to enable analysts to explore how programs are covered over time. Through this visualization, we have enabled analysts to quickly understand which parts of a program are being tested over time, to learn when it is no longer valuable to continue testing, and to see where their test generation is missing important parts of a program.</p>

<p>While our visualization and data analysis scripts can work on any collection of inputs for a program, our web interface does not currently allow a user to upload their own data. As such, a user must clone our repository in order to visualize their own data. In the future, we hope to allow users to directly upload their data and then view the results. An additional area for future work would be to use a more compact representation of our function network graphs such that users can explore larger functions without needing to use the mouse to navigate.</p>
                </div>
            </div>

            <hr>

            <div class="row">
                <div class="col-md-4">
                    <img width="140" height="140" src="img/giorgio.png" class="rounded-circle" alt="Giorgio">
                    <h2>Giorgio Severi</h2>
                    <p></p>
                    <p><a class="btn btn-secondary" href="https://github.com/ClonedOne" role="button">Github &raquo;</a></p>
                </div>
                
                <div class="col-md-4">
                    <img width="140" height="140" src="img/fasano.png" class="rounded-circle" alt="Andrew" style="object-fit: cover">
                    <h2>Andrew Fasano</h2>
                    <p></p>
                    <p><a class="btn btn-secondary" href="https://github.com/andrewfasano" role="button">Github &raquo;</a></p>
                </div>

                <div class="col-md-4">
                    <img width="140" height="140" src="img/talha.JPG" class="rounded-circle" alt="Talha">
                    <h2>Talha Paracha</h2>
                    <p></p>
                    <p><a class="btn btn-secondary" href="#" role="button">Github &raquo;</a></p>
                </div>
            </div>

        </div> <!-- /container -->

        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.bundle.min.js" integrity="sha384-xrRywqdh3PHs8keKZN+8zzc5TX0GRTLCcmivcbNJWm2rs5C8PRhcEn3czEjhAO9o" crossorigin="anonymous"></script>


    </body>

</html>
